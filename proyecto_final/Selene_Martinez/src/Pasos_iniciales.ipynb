{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc2abee",
   "metadata": {},
   "source": [
    "# Proyecto: Phonem Coach: Entrenamiento Personalizado de Fonemas con Análisis Acústico\n",
    "## Diplomado en Inteligencia Artificial y Ciencia de Datos\n",
    "### UNAM, Facultad de Ciencias\n",
    "\n",
    "**Alumna:** Selene Martínez Ventura\n",
    "**Fecha de Entrega:** 25 de abril de 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2afb2",
   "metadata": {},
   "source": [
    "# The initial functions for the complete processing of this project will be listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e65c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import random, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d176921",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join(\"../data\", \"dictionary\")\n",
    "path_train = os.path.join(\"../data\", \"training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1146c14e",
   "metadata": {},
   "source": [
    "## 1. Data dictionary phonemas by accent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b0ffb",
   "metadata": {},
   "source": [
    "The following lists of files by accent were created using the program src/phonema_by_accent.jl, using the database of\n",
    "CMU_ARTIC http://festvox.org/cmu_arctic/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4f2e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    rutas_con_acentos = {\n",
    "        \"../data/phonemas/phonemas_cmu_us_awb_arctic.csv\": \"en-sc\",\n",
    "        \"../data/phonemas/phonemas_cmu_us_bdl_arctic.csv\": \"en-us\",\n",
    "        \"../data/phonemas/phonemas_cmu_us_clb_arctic.csv\": \"en-us\",\n",
    "        \"../data/phonemas/phonemas_cmu_us_jmk_arctic.csv\": \"en-us\",\n",
    "        \"../data/phonemas/phonemas_cmu_us_rms_arctic.csv\": \"en-us\",\n",
    "        \"../data/phonemas/phonemas_cmu_us_slt_arctic.csv\": \"en-us\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da674b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_tokens_fonema_acento(rutas_archivos_con_acento):\n",
    "    \"\"\"\n",
    "    Genera un diccionario de tokens (fonema: [palabras]) organizado por acento.\n",
    "    \"\"\"\n",
    "    tokens_por_acento = {}\n",
    "    for ruta_archivo, acento in rutas_archivos_con_acento.items():\n",
    "        tokens_por_fonema_temp = {}  # Diccionario temporal para acumular sets de palabras\n",
    "        try:\n",
    "            with open(ruta_archivo, 'r', encoding='utf-8') as f:\n",
    "                for linea in f:\n",
    "                    partes = linea.strip().split(',')\n",
    "                    if len(partes) >= 2:\n",
    "                        palabra = partes[0].strip()\n",
    "                        fonema = partes[1].strip()\n",
    "                        fonema_limpio = re.sub(r'\\d+|ˈ|ˌ', '', fonema)\n",
    "\n",
    "                        if fonema_limpio not in tokens_por_fonema_temp:\n",
    "                            tokens_por_fonema_temp[fonema_limpio] = set()\n",
    "                        tokens_por_fonema_temp[fonema_limpio].add(palabra)\n",
    "\n",
    "            # Convertir los sets temporales a listas ordenadas para el acento actual\n",
    "            tokens_por_acento[acento] = {\n",
    "                fonema: sorted(list(palabras))\n",
    "                for fonema, palabras in tokens_por_fonema_temp.items()\n",
    "            }\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"¡Error! No se encontró el archivo: {ruta_archivo}\")\n",
    "\n",
    "    return tokens_por_acento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cded9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = generar_tokens_fonema_acento(rutas_con_acentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los token en un archivo JSON\n",
    "saving_path = os.path.join(path_data, 'tokens_by_accent.json')\n",
    "with open(saving_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(tokens, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"\\nLos tokens por fonema: [palabras] se han guardado en:\\n\", saving_path)\n",
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6c8269",
   "metadata": {},
   "source": [
    "## 2. Fine tunning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71069b7d",
   "metadata": {},
   "source": [
    "Se crean los datasets para realizar un ajuste fino al modelo de lenguaje preentrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20d1b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANGO_F1 = (350, 1000)\n",
    "RANGO_F2 = (1000, 3000)\n",
    "medias = {\n",
    "    \"æ\": {\"f1\": [588, 669], \"f2\": [1952, 2349]},\n",
    "    \"ɪ\": {\"f1\": [427, 483], \"f2\": [2034, 2365]},\n",
    "    \"ʌ\": {\"f1\": [623, 753], \"f2\": [1200, 1426]},\n",
    "}\n",
    "\n",
    "medias_promedio = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d434f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_token = os.path.join(path_data, \"tokens_by_accent.json\")\n",
    "with open(path_token, 'r') as f:\n",
    "    tokens_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39893604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claves en vocales_info_base: dict_keys(['ʌ', 'ɪ', 'æ'])\n"
     ]
    }
   ],
   "source": [
    "vocales_info_base = {}\n",
    "for accent_data in tokens_data.values(): \n",
    "    if isinstance(accent_data, dict): \n",
    "        for fonema, palabras in accent_data.items():\n",
    "            if fonema != \"Fonema\":\n",
    "                palabras_filtradas = [palabra for palabra in palabras if len(palabra) <= 5]\n",
    "                if palabras_filtradas:\n",
    "                    if fonema not in vocales_info_base:\n",
    "                        vocales_info_base[fonema] = {\"palabras\": palabras_filtradas, \"std\": [20, 40]}\n",
    "                    else:\n",
    "                        vocales_info_base[fonema][\"palabras\"].extend(palabras_filtradas)\n",
    "\n",
    "# Eliminar duplicados de las listas de palabras\n",
    "for fonema in vocales_info_base:\n",
    "    vocales_info_base[fonema][\"palabras\"] = list(set(vocales_info_base[fonema][\"palabras\"]))\n",
    "print(\"Claves en vocales_info_base:\", vocales_info_base.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceecf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Primeras entradas de tokens_data:\")\n",
    "# for i, (key, value) in enumerate(tokens_data.items()):\n",
    "#     if i < 5:  \n",
    "#         print(f\"Clave: {key}, Valor: {value}\")\n",
    "#     else:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ed12bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_es = os.path.join(path_train, \"data_es.txt\")\n",
    "\n",
    "save_path_en = os.path.join(path_train, \"data_en.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf5e861",
   "metadata": {},
   "source": [
    "### 2.1 English version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac11a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocales encontradas en vocales_info_base para generar ejemplos: ['ʌ', 'ɪ', 'æ']\n",
      "Se intentaron generar 5000 ejemplos en ../data/training/data_en.txt para fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generar_ejemplo_fine_tuning(vowel_key, medias):\n",
    "    if vowel_key not in medias:\n",
    "        print(f\"Advertencia: La clave '{vowel_key}' no se encuentra en el diccionario 'medias'.\")\n",
    "        return None\n",
    "\n",
    "    f1_range_esperado = medias[vowel_key][\"f1\"]\n",
    "    f2_range_esperado = medias[vowel_key][\"f2\"]\n",
    "    info_base = vocales_info_base[vowel_key]\n",
    "    palabra = random.choice(info_base[\"palabras\"])\n",
    "\n",
    "    # Generar F1 y F2 aleatorios dentro de los rangos del usuario\n",
    "    f1_usuario = random.randint(350, 1000)\n",
    "    f2_usuario = random.randint(1000, 3000)\n",
    "\n",
    "    # Diagnóstico de F1\n",
    "    if f1_usuario < f1_range_esperado[0]:\n",
    "        comentario_f1 = f\"The F1 value of {f1_usuario}Hz is too low for /{vowel_key}/. Try opening your mouth a bit more. \"\n",
    "    elif f1_usuario > f1_range_esperado[1]:\n",
    "        comentario_f1 = f\"The F1 value of {f1_usuario}Hz is too high for /{vowel_key}/. Try relaxing your jaw or opening your mouth slightly less. \"\n",
    "    else:\n",
    "        comentario_f1 = f\"The F1 value of {f1_usuario}Hz is within the expected range for /{vowel_key}/. \"\n",
    "\n",
    "    # Diagnóstico de F2\n",
    "    if f2_usuario < f2_range_esperado[0]:\n",
    "        comentario_f2 = f\"The F2 value of {f2_usuario}Hz is too low for /{vowel_key}/. Try moving your tongue slightly forward. \"\n",
    "    elif f2_usuario > f2_range_esperado[1]:\n",
    "        comentario_f2 = f\"The F2 value of {f2_usuario}Hz is too high for /{vowel_key}/. Try pulling your tongue back or relaxing it. \"\n",
    "    else:\n",
    "        comentario_f2 = f\"The F2 value of {f2_usuario}Hz is within the expected range for /{vowel_key}/. \"\n",
    "\n",
    "    # Generar el prompt y la respuesta\n",
    "    prompt = (\n",
    "        f\"The vowel /{vowel_key}/ was pronounced with F1={f1_usuario}Hz and F2={f2_usuario}Hz. \"\n",
    "        f\"The expected values are F1={f1_range_esperado[0]}-{f1_range_esperado[1]}Hz \"\n",
    "        f\"and F2={f2_range_esperado[0]}-{f2_range_esperado[1]}Hz\\n\"\n",
    "        \"Give feedback on the pronunciation:\\n\"\n",
    "    )\n",
    "\n",
    "    # Cierre motivador\n",
    "    cierre = \"Keep practicing the word and you'll improve quickly. 💪\"\n",
    "\n",
    "    completion = f\"{comentario_f1}{comentario_f2}{cierre}\"\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"completion\": \" \" + completion  # espacio inicial para el fine-tuning\n",
    "    }\n",
    "\n",
    "# Ejemplo de generación del dataset para fine-tuning\n",
    "num_ejemplos = 5000\n",
    "with open(save_path_en, \"w\", encoding=\"utf-8\") as f:\n",
    "    vowels_from_json = list(vocales_info_base.keys())\n",
    "    print(f\"Vocales encontradas en vocales_info_base para generar ejemplos: {vowels_from_json}\")\n",
    "    for i in range(num_ejemplos):\n",
    "        if vowels_from_json:\n",
    "            vowel = random.choice(vowels_from_json)\n",
    "            ejemplo = generar_ejemplo_fine_tuning(vowel, medias)\n",
    "            if ejemplo:\n",
    "                f.write(f\"{ejemplo['prompt']} {ejemplo['completion']}\\n\")\n",
    "            else:\n",
    "                print(f\"La función devolvió None para la vocal: {vowel}\")\n",
    "        else:\n",
    "            print(\"No se encontraron fonemas vocálicos en vocales_info_base para generar ejemplos.\")\n",
    "            break\n",
    "\n",
    "print(f\"Se intentaron generar {num_ejemplos} ejemplos en {save_path_en} para fine-tuning.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1712e7",
   "metadata": {},
   "source": [
    "## 2. Fine tunning  Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6671e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocales encontradas en vocales_info_base para generar ejemplos: ['ʌ', 'ɪ', 'æ']\n",
      "Se intentaron generar 5000 ejemplos en ../data/training/data_es.txt para fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "def generar_ejemplo_fine_tuning(vowel_key, medias):\n",
    "    if vowel_key not in medias:\n",
    "        print(f\"Advertencia: La clave '{vowel_key}' no se encuentra en el diccionario 'medias'.\")\n",
    "        return None\n",
    "\n",
    "    f1_range_esperado = medias[vowel_key][\"f1\"]\n",
    "    f2_range_esperado = medias[vowel_key][\"f2\"]\n",
    "    info_base = vocales_info_base[vowel_key]\n",
    "    palabra = random.choice(info_base[\"palabras\"])\n",
    "\n",
    "    # Generar F1 y F2 aleatorios dentro de los rangos del usuario\n",
    "    f1_usuario = random.randint(350, 1000)\n",
    "    f2_usuario = random.randint(1000, 3000)\n",
    "\n",
    "    # Diagnóstico de F1\n",
    "    if f1_usuario < f1_range_esperado[0]:\n",
    "        comentario_f1 = f\"El valor de F1 de {f1_usuario}Hz es bajo para /{vowel_key}/. Intenta abrir un poco más la boca. \"\n",
    "    elif f1_usuario > f1_range_esperado[1]:\n",
    "        comentario_f1 = f\"El valor de F1 de {f1_usuario}Hz es alto para /{vowel_key}/. Intenta relajar la mandíbula o abrir un poco menos la boca. \"\n",
    "    else:\n",
    "        comentario_f1 = f\"El valor de F1 de {f1_usuario}Hz está dentro del rango esperado para /{vowel_key}/. \"\n",
    "\n",
    "    # Diagnóstico de F2\n",
    "    if f2_usuario < f2_range_esperado[0]:\n",
    "        comentario_f2 = f\"El valor de F2 de {f2_usuario}Hz es bajo para /{vowel_key}/. Intenta mover la lengua ligeramente hacia adelante. \"\n",
    "    elif f2_usuario > f2_range_esperado[1]:\n",
    "        comentario_f2 = f\"El valor de F2 de {f2_usuario}Hz es alto para /{vowel_key}/. Intenta llevar la lengua hacia atrás o relajarla. \"\n",
    "    else:\n",
    "        comentario_f2 = f\"El valor de F2 de {f2_usuario}Hz está dentro del rango esperado para /{vowel_key}/. \"\n",
    "\n",
    "    # Generar el prompt y la respuesta\n",
    "    prompt = (\n",
    "        f\"La vocal {vowel_key} fue pronunciada con F1={f1_usuario}Hz and F2={f2_usuario}Hz. \"\n",
    "        f\"Los valores esperados son F1={f1_range_esperado[0]}-{f1_range_esperado[1]}Hz \"\n",
    "        f\"y F2={f2_range_esperado[0]}-{f2_range_esperado[1]}Hz \\n\"\n",
    "        \"Give feedback on the pronunciation:\\n\"\n",
    "    )\n",
    "\n",
    "    # Cierre motivador\n",
    "    cierre = \"Keep practicing the word and you'll improve quickly. 💪\"\n",
    "\n",
    "    completion = f\"{comentario_f1}{comentario_f2}{cierre}\"\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"completion\": \" \" + completion  \n",
    "    }\n",
    "\n",
    "# Ejemplo de generación del dataset para fine-tuning\n",
    "num_ejemplos = 5000\n",
    "with open(save_path_es, \"w\", encoding=\"utf-8\") as f:\n",
    "    vowels_from_json = list(vocales_info_base.keys())\n",
    "    print(f\"Vocales encontradas en vocales_info_base para generar ejemplos: {vowels_from_json}\")\n",
    "    for i in range(num_ejemplos):\n",
    "        if vowels_from_json:\n",
    "            vowel = random.choice(vowels_from_json)\n",
    "            ejemplo = generar_ejemplo_fine_tuning(vowel, medias)\n",
    "            if ejemplo:\n",
    "                f.write(f\"{ejemplo['prompt']} {ejemplo['completion']}\\n\")\n",
    "            else:\n",
    "                print(f\"La función devolvió None para la vocal: {vowel}\")\n",
    "        else:\n",
    "            print(\"No se encontraron fonemas vocálicos en vocales_info_base para generar ejemplos.\")\n",
    "            break\n",
    "\n",
    "print(f\"Se intentaron generar {num_ejemplos} ejemplos en {save_path_es} para fine-tuning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee6bb71",
   "metadata": {},
   "source": [
    "# 3. Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1fc7b9",
   "metadata": {},
   "source": [
    "#### 3.1 Spanish version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "import shutil\n",
    "\n",
    "#save_path_es = \"/content/drive/MyDrive/ProyectoF/dataset_es.txt\" \n",
    "\n",
    "# Cargar tokenizer y modelo base\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Cargar y tokenizar dataset\n",
    "dataset = load_dataset(\"text\", data_files={\"train\": save_path_es})\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"],\n",
    "                     return_special_tokens_mask=True,\n",
    "                     truncation=True,\n",
    "                     max_length=256)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "final_model_path = os.path.join(\"../data\", \"gpt2-pron-feedback_es\")\n",
    "\n",
    "# Argumentos de entrenamiento SIN checkpoints intermedios\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=final_model_path,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=1,\n",
    "    save_strategy=\"no\",  # No checkpoints\n",
    "    logging_steps=10,\n",
    "    logging_dir='./logs',\n",
    "    learning_rate=3e-5,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Entrenador\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "trainer.train()\n",
    "\n",
    "# Guardar modelo y tokenizer\n",
    "model.save_pretrained(final_model_path)\n",
    "tokenizer.save_pretrained(final_model_path)\n",
    "\n",
    "# Comprimir para descargar\n",
    "#shutil.make_archive(final_model_path, 'zip', final_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8067424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_path_en = os.path.join(\"../data\", \"gpt2-pron-feedback_en\")\n",
    "final_model_path_es = os.path.join(\"../data\", \"gpt2-pron-feedback_es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859a992",
   "metadata": {},
   "source": [
    "##### Trying model\n",
    "Prueba del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0803023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# Cargar modelo y tokenizer entrenados\n",
    "model_path = final_model_path_es\n",
    "tokenizer = final_model_path_es\n",
    "generator = pipeline(\"text-generation\", model=model_path, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4021ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme = \"ae\"\n",
    "input_word = \"cat\"\n",
    "f1 = 3000\n",
    "f2 = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ed01c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La vocal /ae/ fue pronunciada con F1=3000Hz y F2=2000Hz. La palabra practicada fue 'cat'. Se detectó que el valor de F1 no está dentro del rango esperado. Brinda una sugerencia específica y clara para mejorar la pronunciación de esta vocal en ese contexto.\n",
      "Respuesta: ¡La apertura de tu boca es excelente, ¡Sigue así! 🎉 ʌ con F1=1017Hz y F2=1023Hz., Se práctico la palabra 'lover'. ¡La apertura de tu boca es excelente, �\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    f\"La vocal /{phoneme}/ fue pronunciada con F1={int(f1)}Hz y F2={int(f2)}Hz. \"\n",
    "    f\"La palabra practicada fue '{input_word}'. \"\n",
    "    f\"Se detectó que el valor de F1 no está dentro del rango esperado. \"\n",
    "    \"Brinda una sugerencia específica y clara para mejorar la pronunciación de esta vocal en ese contexto.\\nRespuesta:\"\n",
    ")\n",
    "\n",
    "respuesta = generator(prompt, max_new_tokens=70, do_sample=True, temperature=0.5)[0][\"generated_text\"]\n",
    "print(respuesta)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(ProyectoF 3.12)",
   "language": "python",
   "name": "pipenv-3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
