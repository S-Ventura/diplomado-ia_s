{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee538e072b6a4d8d9c3e8db6f27933c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70af9c6274f54eb4901441dd21097d5a",
              "IPY_MODEL_9f668403d8d641ac88228aef5a4b9042",
              "IPY_MODEL_f790a4b90e014d94910dff4becd12a34"
            ],
            "layout": "IPY_MODEL_c93c00be25bc4d478d1a819341708956"
          }
        },
        "70af9c6274f54eb4901441dd21097d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8822ad4f12f84c4b98608a868669db62",
            "placeholder": "​",
            "style": "IPY_MODEL_72f52ef7f75845caae66047e0c5537b3",
            "value": "Map: 100%"
          }
        },
        "9f668403d8d641ac88228aef5a4b9042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7791201723c4bd38a0d6d5206bdff40",
            "max": 1121,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d208bb0f7a94af1965a0c9d11209edf",
            "value": 1121
          }
        },
        "f790a4b90e014d94910dff4becd12a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92b0562acef14aceb897721e3dbbb49d",
            "placeholder": "​",
            "style": "IPY_MODEL_67b601c666624d8e8ba9a1563fb22eae",
            "value": " 1121/1121 [00:00&lt;00:00, 2023.62 examples/s]"
          }
        },
        "c93c00be25bc4d478d1a819341708956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8822ad4f12f84c4b98608a868669db62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f52ef7f75845caae66047e0c5537b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7791201723c4bd38a0d6d5206bdff40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d208bb0f7a94af1965a0c9d11209edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92b0562acef14aceb897721e3dbbb49d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67b601c666624d8e8ba9a1563fb22eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f24040a2613e45798be1b7d2a47fde7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ef1b47f19b44de080089757e5908f62",
              "IPY_MODEL_c08ed843a77f43198839df12eb0fedcf",
              "IPY_MODEL_5063eb02c1ec4460b367241887ffe1e5"
            ],
            "layout": "IPY_MODEL_95277191bbb2457e923f26931fdf4b18"
          }
        },
        "6ef1b47f19b44de080089757e5908f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98940c7ffa80419e92dfe4bbfcf28941",
            "placeholder": "​",
            "style": "IPY_MODEL_cae0b42338c74ee8974460e2ae46d124",
            "value": "Generating train split: "
          }
        },
        "c08ed843a77f43198839df12eb0fedcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_093e1ab0a7c142e78567f71b00af3841",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0b20a01c9ec44aaade653cb0db85dc4",
            "value": 1
          }
        },
        "5063eb02c1ec4460b367241887ffe1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e145a195c9848c4945e9bc0b68a092b",
            "placeholder": "​",
            "style": "IPY_MODEL_a892e422cf054037bec5783c21b5e086",
            "value": " 352/0 [00:00&lt;00:00, 7047.20 examples/s]"
          }
        },
        "95277191bbb2457e923f26931fdf4b18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98940c7ffa80419e92dfe4bbfcf28941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cae0b42338c74ee8974460e2ae46d124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "093e1ab0a7c142e78567f71b00af3841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b0b20a01c9ec44aaade653cb0db85dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e145a195c9848c4945e9bc0b68a092b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a892e422cf054037bec5783c21b5e086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2de029f5fceb4457a18036d2fbe0030b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e4f9b09156644939de13eacd3966833",
              "IPY_MODEL_3c0597b9858043d2aaa6481512a15c07",
              "IPY_MODEL_347e4075dd684e558eeb775f198a0229"
            ],
            "layout": "IPY_MODEL_58c4059239394cd69377aa5e14d3f270"
          }
        },
        "8e4f9b09156644939de13eacd3966833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ed0d18be5f46c785b79162e7228e74",
            "placeholder": "​",
            "style": "IPY_MODEL_fd787d37108b49608a75aed1422be54d",
            "value": "Map: 100%"
          }
        },
        "3c0597b9858043d2aaa6481512a15c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09e25a5c198c48b3b6ab6aeb73696bb1",
            "max": 352,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88ef1ac6c5c04f78a9e44c59fbed7eb2",
            "value": 352
          }
        },
        "347e4075dd684e558eeb775f198a0229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3876ee0b6f9e4ae58ffc14a008794161",
            "placeholder": "​",
            "style": "IPY_MODEL_a866bf0484f4461f99e6ca198dd54c94",
            "value": " 352/352 [00:00&lt;00:00, 1701.09 examples/s]"
          }
        },
        "58c4059239394cd69377aa5e14d3f270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2ed0d18be5f46c785b79162e7228e74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd787d37108b49608a75aed1422be54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09e25a5c198c48b3b6ab6aeb73696bb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88ef1ac6c5c04f78a9e44c59fbed7eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3876ee0b6f9e4ae58ffc14a008794161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a866bf0484f4461f99e6ca198dd54c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6k3dTKy-xn6",
        "outputId": "5c2977a7-7f57-4267-d686-851b51291f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses) (1.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, sacremoses, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 sacremoses-0.1.1 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets sacremoses\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset('text', data_files={'train': '/content/comorbidity_recommendation_dataset.txt'})\n",
        "\n",
        "# Load BioGPT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/biogpt')\n",
        "\n",
        "# Tokenize\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, max_length=128)\n",
        "\n",
        "tokenized_dataset = dataset['train'].map(tokenize_function, batched=True, remove_columns=['text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ee538e072b6a4d8d9c3e8db6f27933c6",
            "70af9c6274f54eb4901441dd21097d5a",
            "9f668403d8d641ac88228aef5a4b9042",
            "f790a4b90e014d94910dff4becd12a34",
            "c93c00be25bc4d478d1a819341708956",
            "8822ad4f12f84c4b98608a868669db62",
            "72f52ef7f75845caae66047e0c5537b3",
            "e7791201723c4bd38a0d6d5206bdff40",
            "7d208bb0f7a94af1965a0c9d11209edf",
            "92b0562acef14aceb897721e3dbbb49d",
            "67b601c666624d8e8ba9a1563fb22eae"
          ]
        },
        "id": "NYPg0Bbp--o5",
        "outputId": "e6e95f61-709c-4a6c-cbf9-956b576826e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1121 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee538e072b6a4d8d9c3e8db6f27933c6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "# Load BioGPT model\n",
        "model = AutoModelForCausalLM.from_pretrained('microsoft/biogpt')\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/mnt/data/biogpt_comorbidity_model',\n",
        "    num_train_epochs=6,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=5e-5,\n",
        "    fp16=True,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    logging_steps=100\n",
        ")\n"
      ],
      "metadata": {
        "id": "xf1g4PZZ_S4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "d5YUReGj_X6H",
        "outputId": "14f66cbb-74aa-4a90-eb09-069034564a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1680' max='1680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1680/1680 14:53, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.940800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.514700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.426600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.867900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.121600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.816300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.553200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.573400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.492200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.396900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.417100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.317200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.294300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.298500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.246200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.228900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1680, training_loss=0.6957948310034615, metrics={'train_runtime': 893.9779, 'train_samples_per_second': 7.524, 'train_steps_per_second': 1.879, 'total_flos': 301055017721856.0, 'train_loss': 0.6957948310034615, 'epoch': 5.9812667261373775})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('/content/biogpt_comorbidity_model_final')\n",
        "tokenizer.save_pretrained('/content/biogpt_comorbidity_model_final')\n",
        "print('✅ Model and tokenizer saved successfully.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wImw-CkH_aOp",
        "outputId": "3fdd1f60-e7fe-4cc6-fe56-4c872819ce57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and tokenizer saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "# Ruta donde se guardó el modelo entrenado\n",
        "model_path = \"/content/biogpt_comorbidity_model_final\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "# Crear pipeline de generación\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48id84xoCCti",
        "outputId": "a13f3b4a-daec-41fa-d0e2-a59d9fd9ccfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo: para diabetes\n",
        "condition = \"diabetes\"\n",
        "prompt = (\n",
        "    f\"<|startoftext|>\\n\"\n",
        "    f\"[CONDITION]: {condition}\\n\"\n",
        "    \"[PROMPT]: Provide a COVID-19-specific health recommendation.\\n\"\n",
        "    \"[RECOMMENDATION]:\"\n",
        ")\n",
        "\n",
        "# Generar recomendación\n",
        "output = generator(prompt, max_length=100, do_sample=True, temperature=0.7)\n",
        "recommendation = output[0]['generated_text'].split(\"[RECOMMENDATION]:\")[-1].split(\"<|endoftext|>\")[0].strip()\n",
        "\n",
        "print(f\"✅ Recommendation for {condition.upper()}:\\n{recommendation}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p--9Y8IUCIom",
        "outputId": "2445d8fb-f42e-4ad3-9d0e-79bc24ea75e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Recommendation for DIABETES:\n",
            "Hello, For diabetes, i do not recommend to self-isolate. Self-quarantine is important, but not a substitute for vaccine. Get tested if you develop symptoms. If you have a non-resolving pneumonia, then do not recommend to self-isolate. Self-quarantine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comorbidities = [\"diabetes\", \"asthma\", \"cardiovascular\", \"obesity\", \"smoking\"]\n",
        "\n",
        "for cond in comorbidities:\n",
        "    prompt = (\n",
        "        f\"<|startoftext|>\\n\"\n",
        "        f\"[CONDITION]: {cond}\\n\"\n",
        "        \"[PROMPT]: Provide a COVID-19-specific health recommendation.\\n\"\n",
        "        \"[RECOMMENDATION]:\"\n",
        "    )\n",
        "    output = generator(prompt, max_length=100, do_sample=True, temperature=0.7)\n",
        "    recommendation = output[0]['generated_text'].split(\"[RECOMMENDATION]:\")[-1].split(\"<|endoftext|>\")[0].strip()\n",
        "    print(f\"\\n🩺 Recommendation for {cond.upper()}:\\n{recommendation}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maXCFWGRCUK-",
        "outputId": "0767f1c3-8688-412c-f820-6f7a9115d52d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🩺 Recommendation for DIABETES:\n",
            "Hello, For your diabetes, keep A1c as low as possible, do everything you can to support gut health and immunity, increase supplements that increase resistance to viruses, and use social distancing to minimize contact with others. If you have a sore throat for a few days that gets worse every\n",
            "\n",
            "🩺 Recommendation for ASTHMA:\n",
            "Hello, According to the history it might be a viral situation or an allergy. Continue the current treatment guidelines as they were developed. Get tested if you start a new treatment or change of treatment. If you have a viral situation or an allergy you should go for a test and start\n",
            "\n",
            "🩺 Recommendation for CARDIOVASCULAR:\n",
            "Thanks for your question on Healthcare Magic. I can understand your concern. Since you are a well controlled diabetic, your symptoms are not under control. Regular exercise and adequate sleep are important for your health. But, if you get infected, your symptoms are more likely to be due to uncontrolled infections\n",
            "\n",
            "🩺 Recommendation for OBESITY:\n",
            "In brief: Sort of. If you are a non-medical term to describe a very mild case of pneumonia, it's typically called atypical pneumonia. It is usually called viral pneumonia because it usually takes more than 1 week for complete recovery. Most people with viral pneumonia do not have fever, cough\n",
            "\n",
            "🩺 Recommendation for SMOKING:\n",
            "Hello, The most possible issue here is lung infection, which can complicate as pneumonia. Actually, pneumonia is often caused by bacteria called Mycoplasma pneumoniae, which can cause pneumonia in up to 80% of cases. So, it is advisable to consult pulmonologist and discuss over the telephone regarding this\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Cargar tu dataset estructurado (lista de ejemplos tipo <|startoftext|>...)\n",
        "with open(\"comorbidity_recommendation_dataset.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_data = f.read().split(\"<|startoftext|>\")\n",
        "\n",
        "filtered_examples = []\n",
        "\n",
        "for entry in raw_data:\n",
        "    if \"[RECOMMENDATION]:\" not in entry:\n",
        "        continue\n",
        "\n",
        "    match = re.search(r\"\\[RECOMMENDATION\\]:(.*)<\\|endoftext\\|>\", entry, re.DOTALL)\n",
        "    if not match:\n",
        "        continue\n",
        "\n",
        "    rec = match.group(1).strip().lower()\n",
        "\n",
        "    # Frases que indican lenguaje no médico o fórmulas sociales\n",
        "    bad_phrases = [\n",
        "        \"thank you\", \"hello\", \"ask a doctor\", \"healthcare magic\",\n",
        "        \"wish you good health\", \"thanks. thanks.\", \"have a nice day\",\n",
        "        \"i can understand your concern\", \"i will be happy to help\"\n",
        "    ]\n",
        "\n",
        "    if any(phrase in rec for phrase in bad_phrases):\n",
        "        continue\n",
        "\n",
        "    # Descartar si la recomendación es muy corta\n",
        "    if len(rec.split()) < 8:\n",
        "        continue\n",
        "\n",
        "    filtered_examples.append(\"<|startoftext|>\" + entry.strip())\n",
        "\n",
        "# Guardar nuevo dataset limpio\n",
        "with open(\"cleaned_comorbidity_dataset.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(filtered_examples))\n",
        "\n",
        "print(f\"✅ Cleaned dataset with {len(filtered_examples)} examples saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1T4q5GxHnUs",
        "outputId": "3dbc3203-bf8a-4492-907c-2b6f45b9cc5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cleaned dataset with 82 examples saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset('text', data_files={'train': '/content/cleaned_comorbidity_dataset.txt'})\n",
        "\n",
        "# Load BioGPT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/biogpt')\n",
        "\n",
        "# Tokenize\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, max_length=128)\n",
        "\n",
        "tokenized_dataset = dataset['train'].map(tokenize_function, batched=True, remove_columns=['text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "f24040a2613e45798be1b7d2a47fde7d",
            "6ef1b47f19b44de080089757e5908f62",
            "c08ed843a77f43198839df12eb0fedcf",
            "5063eb02c1ec4460b367241887ffe1e5",
            "95277191bbb2457e923f26931fdf4b18",
            "98940c7ffa80419e92dfe4bbfcf28941",
            "cae0b42338c74ee8974460e2ae46d124",
            "093e1ab0a7c142e78567f71b00af3841",
            "b0b20a01c9ec44aaade653cb0db85dc4",
            "4e145a195c9848c4945e9bc0b68a092b",
            "a892e422cf054037bec5783c21b5e086",
            "2de029f5fceb4457a18036d2fbe0030b",
            "8e4f9b09156644939de13eacd3966833",
            "3c0597b9858043d2aaa6481512a15c07",
            "347e4075dd684e558eeb775f198a0229",
            "58c4059239394cd69377aa5e14d3f270",
            "d2ed0d18be5f46c785b79162e7228e74",
            "fd787d37108b49608a75aed1422be54d",
            "09e25a5c198c48b3b6ab6aeb73696bb1",
            "88ef1ac6c5c04f78a9e44c59fbed7eb2",
            "3876ee0b6f9e4ae58ffc14a008794161",
            "a866bf0484f4461f99e6ca198dd54c94"
          ]
        },
        "outputId": "0177e22d-5521-41ba-b77a-7ca388b3dfee",
        "id": "vpRXKugAHvnS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f24040a2613e45798be1b7d2a47fde7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/352 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2de029f5fceb4457a18036d2fbe0030b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "# Load BioGPT model\n",
        "model = AutoModelForCausalLM.from_pretrained('microsoft/biogpt')\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/mnt/data/biogpt_comorbidity_model',\n",
        "    num_train_epochs=6,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=5e-5,\n",
        "    fp16=True,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    logging_steps=100\n",
        ")\n"
      ],
      "metadata": {
        "id": "sawraA8JH27o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "28693544-5fdc-40d7-d894-be90f44f978c",
        "id": "TPVNjPFxH7Qa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='528' max='528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [528/528 06:06, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.137100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.024200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.649600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.358600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.247500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=528, training_loss=0.8484438441016457, metrics={'train_runtime': 366.6676, 'train_samples_per_second': 5.76, 'train_steps_per_second': 1.44, 'total_flos': 114121353314304.0, 'train_loss': 0.8484438441016457, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('/content/clean_biogpt_comorbidity_model_final')\n",
        "tokenizer.save_pretrained('/content/clean_biogpt_comorbidity_model_final')\n",
        "print('✅ Model and tokenizer saved successfully.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fec97e5d-9b03-4d79-c6f2-906afad14a00",
        "id": "jWoc4DEyJVxz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and tokenizer saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "# Ruta donde se guardó el modelo entrenado\n",
        "model_path = \"/content/clean_biogpt_comorbidity_model_final\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "# Crear pipeline de generación\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c304e735-b3e0-41bb-cd73-50b4d6cba325",
        "id": "kni6ix_rJfLe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo: para diabetes\n",
        "condition = \"diabetes\"\n",
        "prompt = (\n",
        "    f\"<|startoftext|>\\n\"\n",
        "    f\"[CONDITION]: {condition}\\n\"\n",
        "    \"[PROMPT]: Provide a COVID-19-specific health recommendation.\\n\"\n",
        "    \"[RECOMMENDATION]:\"\n",
        ")\n",
        "\n",
        "# Generar recomendación\n",
        "output = generator(prompt, max_length=100, do_sample=True, temperature=0.7)\n",
        "recommendation = output[0]['generated_text'].split(\"[RECOMMENDATION]:\")[-1].split(\"<|endoftext|>\")[0].strip()\n",
        "\n",
        "print(f\"✅ Recommendation for {condition.upper()}:\\n{recommendation}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0098985e-27b9-4dcf-8a6d-672b8ec4248c",
        "id": "8pyIL-vJJm-a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Recommendation for DIABETES:\n",
            "diabetes. High-affinity receptor for coronavirus, the receptor for the virus, is expressed in the lung, and if you are well controlled one's immunity to COVID should not be compromised. Poorly controlled diabetics, especially with complications, may be at greater risk for complications. Regular glucose control and intermittent ph\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comorbidities = [\"diabetes\", \"asthma\", \"cardiovascular\", \"obesity\", \"smoking\"]\n",
        "\n",
        "for cond in comorbidities:\n",
        "    prompt = (\n",
        "        f\"<|startoftext|>\\n\"\n",
        "        f\"[CONDITION]: {cond}\\n\"\n",
        "        \"[PROMPT]: Provide a COVID-19-specific health recommendation.\\n\"\n",
        "        \"[RECOMMENDATION]:\"\n",
        "    )\n",
        "    output = generator(prompt, max_length=100, do_sample=True, temperature=0.7)\n",
        "    recommendation = output[0]['generated_text'].split(\"[RECOMMENDATION]:\")[-1].split(\"<|endoftext|>\")[0].strip()\n",
        "    print(f\"\\n🩺 Recommendation for {cond.upper()}:\\n{recommendation}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247ae0db-c8c2-4ff6-922d-4935e5927fc4",
        "id": "6Ale9mV7Jx-m"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🩺 Recommendation for DIABETES:\n",
            "Diabetes. Type 1 or 2 if managed well and treated can still maintain good immunity. If either are out of control then infections of any type more likely......................, and also if you are in contro\n",
            "\n",
            "🩺 Recommendation for ASTHMA:\n",
            "In brief: Asthma is a chronic lung disease which carries some increased risk with COVID-19. Although the evidence is clear that people with chronic lung disease do worse in a respiratory disease outbreak, it is not clear if this is because they are more fragile or have difficulty breathing. High risk with underlying medical\n",
            "\n",
            "🩺 Recommendation for CARDIOVASCULAR:\n",
            "Coronavirus-specific health recommendation. The general population should start to get infections early in the course of the disease. If you have fever over 100F, call your PCP right away. Follow the following guidelines: https: / / www.healthtap.com / blog / covid-19-care-\n",
            "\n",
            "🩺 Recommendation for OBESITY:\n",
            "In brief: Not quite that way. If you are having sex with someone who has Covid-19 you are quite at risk of getting it. If you have diabetes it's ok.And if you have hypertension they are also quite at risk of it's being struck by it. Would\n",
            "\n",
            "🩺 Recommendation for SMOKING:\n",
            "smoking. Although the evidence is not conclusive, it is clear that smoking increases the risk of complications from COVID-19. The most important way to prevent smoking from coming into contact with someone who is infected is to stay in a home where the virus is unlikely to be transmitted. Also, giving up the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo: para diabetes\n",
        "comorbidities = [\"diabetes\", \"asthma\", \"cardiovascular\", \"obesity\", \"smoking\"]\n",
        "\n",
        "for cond in comorbidities:\n",
        "#condition = \"diabetes\"\n",
        "  prompt = (\n",
        "      \"<|startoftext|>\\n\"\n",
        "      f\"[CONDITION]: {cond}\\n\"\n",
        "      \"[PROMPT]: Provide a clear and actionable health recommendation for a COVID-19 patient with this condition.\\n\"\n",
        "      f\"[RECOMMENDATION]: For patients with {cond}, it is important to\"\n",
        "  )\n",
        "\n",
        "  # Generar recomendación\n",
        "  output = generator(prompt, max_length=100, do_sample=True, temperature=0.7)\n",
        "  recommendation = output[0]['generated_text'].split(\"[RECOMMENDATION]:\")[-1].split(\"<|endoftext|>\")[0].strip()\n",
        "\n",
        "  print(f\"✅ Recommendation for {cond.upper()}:\\n{recommendation}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab06589a-bb35-4471-bd9e-d55542e08a45",
        "id": "8-0J33glO5h_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Recommendation for DIABETES:\n",
            "For patients with diabetes, it is important to follow appropriate diabetic-specific health recommendations. Most of the information available on this topic comes from expert opinion. It is clear that if you are well controlled, you can still maintain good immunity. However, if your diabetes\n",
            "✅ Recommendation for ASTHMA:\n",
            "For patients with asthma, it is important to follow appropriate disease-management guidelines. They should get their inhalers appropriately (including an urgent inhaler). If symptoms do not improve with treatment, please call your PCP and follow his / her directions completely..\n",
            "✅ Recommendation for CARDIOVASCULAR:\n",
            "For patients with cardiovascular, it is important to consider your diabetes status, as well as the other comorbidities that can affect a patient's response to infection. If you are well controlled, you will be fine............\n",
            "✅ Recommendation for OBESITY:\n",
            "For patients with obesity, it is important to consider the effects of obesity on their immune system and ability to handle viral infection. If you are a non-smoking diabetic, you are at higher risk for complications. If you are a non-smoking diabetic, you\n",
            "✅ Recommendation for SMOKING:\n",
            "For patients with smoking, it is important to keep smoking as low as possible, and to give up the pack of cigarettes. If you are younger, do not smoke, do not have chronic lung problems, or do not have fever, cough or difficulty breathing do\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cond in comorbidities:\n",
        "    prompt = (\n",
        "        \"<|startoftext|>\\n\"\n",
        "        f\"[CONDITION]: {cond}\\n\"\n",
        "        \"[PROMPT]: Provide a clear and actionable health recommendation for a COVID-19 patient with this condition.\\n\"\n",
        "        f\"[RECOMMENDATION]: For patients with {cond}, it is important to\"\n",
        "    )\n",
        "    output = generator(prompt, max_length=180, do_sample=True, temperature=0.6, top_k=50, top_p=0.9)\n",
        "    text = output[0]['generated_text']\n",
        "    recommendation = text.split(\"[RECOMMENDATION]:\")[-1].split(\"<|endoftext|>\")[0].strip()\n",
        "    print(f\"\\n✅ Recommendation for {cond.upper()}:\\n{recommendation}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90tGJ0QpRFQf",
        "outputId": "97c7adcc-81ee-4697-e7c8-9652c560b844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Recommendation for DIABETES:\n",
            "For patients with diabetes, it is important to keep A1c as low as possible, do everything you can to support gut health and immunity, and increase supplements that increase resistance to viruses. Be positive......................, increase supplements that increase resistance to viruses............................................................., increase\n",
            "\n",
            "✅ Recommendation for ASTHMA:\n",
            "For patients with asthma, it is important to follow appropriate asthma treatment guidelines. High-risk patients, such as those with uncontrolled asthma, chronic diseases or compromised immune system, are at higher risk for complications. Regular inhaled steroids (if available) along with systemic anti-inflammatory drugs (if available) should be used to control the disease. Regular inhaled steroids can be used as a boost to the regular inhaled steroids. If symptoms go bad, it's ER time. If you are having sex with someone who is postive htat you know, have you travelled? do you have a fever? do you have cough? do you have difficulty breathing? do you\n",
            "\n",
            "✅ Recommendation for CARDIOVASCULAR:\n",
            "For patients with cardiovascular, it is important to realize that this is not the case. Rather, the situation is that a patient with a medical condition like intermittent asthma does worse in a COVID-19 outbreak. Based on the existing evidence and our own experience, it is recommendable to assume that you are at higher risk and strict protection are needed. Smoking, hypertension, diabetes, obesity or compromised immune system are also risk factors to be considered. If you have a medical condition like asthma, you are at higher risk and strict protection should be taken. If you have a medical condition like diabetes, you are at lower risk and strict protection should be taken...\n",
            "\n",
            "✅ Recommendation for OBESITY:\n",
            "For patients with obesity, it is important to keep A1c as low as possible, do everything you can to support gut health and immunity, and increase supplements that increase resistance to viruses. If you have a sore throat and a fever, call your General Physician and follow his / her directions completely..........................................................................\n",
            "\n",
            "✅ Recommendation for SMOKING:\n",
            "For patients with smoking, it is important to keep up the good work and do not smoke. If you have a sore throat and a fever, call your General Physician and follow his / her directions completely. Stay calm. If you have a fever, call your General Physician and follow his / her directions completely. Stay calm. Would you like to video or text chat with me? Would you like to video or text chat with me? Would you like to video or text chat with me? Would you like to video or text chat with me? Would you like to video or text chat with\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/clean_biogpt_comorbidity_model_final.zip /content/clean_biogpt_comorbidity_model_final\n",
        "\n",
        "!zip -r /content/biogpt_comorbidity_model_final.zip /content/biogpt_comorbidity_model_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP5Q5CvhK8WP",
        "outputId": "c62928b8-3fb3-4b1a-e312-65421fd5f906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/clean_biogpt_comorbidity_model_final/ (stored 0%)\n",
            "  adding: content/clean_biogpt_comorbidity_model_final/model.safetensors (deflated 7%)\n",
            "  adding: content/clean_biogpt_comorbidity_model_final/tokenizer_config.json (deflated 73%)\n",
            "  adding: content/clean_biogpt_comorbidity_model_final/merges.txt (deflated 60%)\n",
            "  adding: content/clean_biogpt_comorbidity_model_final/special_tokens_map.json (deflated 51%)\n",
            "  adding: content/clean_biogpt_comorbidity_model_final/config.json (deflated 49%)\n",
            "  adding: content/clean_biogpt_comorbidity_model_final/generation_config.json (deflated 29%)\n",
            "  adding: content/clean_biogpt_comorbidity_model_final/vocab.json (deflated 70%)\n",
            "  adding: content/biogpt_comorbidity_model_final/ (stored 0%)\n",
            "  adding: content/biogpt_comorbidity_model_final/model.safetensors (deflated 7%)\n",
            "  adding: content/biogpt_comorbidity_model_final/tokenizer_config.json (deflated 73%)\n",
            "  adding: content/biogpt_comorbidity_model_final/merges.txt (deflated 60%)\n",
            "  adding: content/biogpt_comorbidity_model_final/special_tokens_map.json (deflated 82%)\n",
            "  adding: content/biogpt_comorbidity_model_final/config.json (deflated 49%)\n",
            "  adding: content/biogpt_comorbidity_model_final/generation_config.json (deflated 29%)\n",
            "  adding: content/biogpt_comorbidity_model_final/vocab.json (deflated 70%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset('text', data_files={'train': '/content/medical_explainer_dataset.txt'})\n",
        "\n",
        "# Load BioGPT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/biogpt')\n",
        "\n",
        "# Tokenize\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, max_length=256)\n",
        "\n",
        "tokenized_dataset = dataset['train'].map(tokenize_function, batched=True, remove_columns=['text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_5vVPM6XDAR",
        "outputId": "8dcb9544-df07-4703-9ca9-f4c9c9bfcd9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade sympy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "0zD2WD6HXarJ",
        "outputId": "27ad28fc-f219-4622-8985-73d51f16120b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Collecting sympy\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy) (1.3.0)\n",
            "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sympy-1.13.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sympy"
                ]
              },
              "id": "d5e503877a364358bfdaffa50717df55"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "# Load BioGPT model\n",
        "model = AutoModelForCausalLM.from_pretrained('microsoft/biogpt')\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/mnt/data/biogpt_explainer_model',\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=5e-5,\n",
        "    fp16=True,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    logging_steps=100\n",
        ")\n"
      ],
      "metadata": {
        "id": "NJvJB7bPXKnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "bxxvNB3xXz5y",
        "outputId": "9f2b19d1-6b9d-4fab-a5cd-7f81c8fc0cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='560' max='560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [560/560 07:22, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.278200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.498400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.256300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.147700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.112200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=560, training_loss=0.42067699687821525, metrics={'train_runtime': 443.384, 'train_samples_per_second': 5.052, 'train_steps_per_second': 1.263, 'total_flos': 264770391367680.0, 'train_loss': 0.42067699687821525, 'epoch': 10.0})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('/content/biogpt_explainer_model_final')\n",
        "tokenizer.save_pretrained('/content/biogpt_explainer_model_final')\n",
        "print('✅ Model and tokenizer saved successfully.')\n"
      ],
      "metadata": {
        "id": "gCEYNXwSYmiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089a4e49-b9fc-4a64-858d-a8486ce1a057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and tokenizer saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "# Cargar modelo entrenado\n",
        "model_path = \"/content/biogpt_explainer_model_final\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "explainer = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Lista de comorbilidades para probar\n",
        "comorbidities = [\n",
        "    \"diabetes\", \"asthma\", \"hypertension\", \"cardiovascular disease\",\n",
        "    \"obesity\", \"smoking\", \"pneumonia\", \"immune suppression\"\n",
        "]\n",
        "\n",
        "for cond in comorbidities:\n",
        "    prompt = (\n",
        "        \"<|startoftext|>\\n\"\n",
        "        f\"[PROMPT]: How does {cond} affect COVID-19 outcomes?\\n\"\n",
        "        \"[EXPLANATION]:\"\n",
        "    )\n",
        "    output = explainer(prompt, max_length=200, do_sample=True, temperature=0.7)\n",
        "    explanation = output[0]['generated_text'].split(\"[EXPLANATION]:\")[-1].split(\"<|endoftext|>\")[0].strip()\n",
        "\n",
        "    print(f\"\\n🧠 Explanation for {cond.upper()}:\\n{explanation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqM9I_cIZBWR",
        "outputId": "d9108d2b-fea4-4a08-95a0-dc2ecdcd288b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧠 Explanation for DIABETES:\n",
            "The current mortality rate of patients suffering from coronavirus disease 2019 (COVID-19) is between 45% and 92%, with most dying within the first two weeks of the illness. In an effort to combat such an alarmingly high mortality rate, various treatment therapies such as low tidal volume ventilation strategies, corticosteroid therapy, and use of nitric oxide (NO) have been attempted in the management of patients with COVID-19. Three cases which were admitted to the ICU and confirmed to have COVID-19 were unable to be weaned from ventilatory support, and nitric oxide therapy was initiated. It improved patients' oxygenation for short periods of time but did not affect the mortality. The patients could not be weaned from the ventilator and expired. The patients could not be weaned from the ventilator and expired. The patients could not be weaned from the ventilator and expired. The\n",
            "\n",
            "🧠 Explanation for ASTHMA:\n",
            "BACKGROUND: Asthma is one of the risk factors for severe pneumonia and death in patients with COVID-19. However, which factors affect COVID-19 patients differently? METHODS: We conducted a retrospective cohort study of 153 patients with COVID-19 admitted to a tertiary referral hospital in Wuhan, China. The status of asthma was determined by review of medical records. RESULTS: Compared to patients without asthma, the patients with asthma were older and non-atopic and had a higher prevalence of comorbid sinusitis, COPD, or pneumonia. Compared to patients without asthma, the patients with asthma had a higher incidence of comorbid sinusitis, COPD, or pneumonia and a higher rate of smoking. Multivariate analysis identified smoking, comorbid sinusitis, COPD, or pneumonia and a higher level of hemoglobin A1c as independent factors associated with a higher risk of mortality. Compared to patients without asthma, the patients\n",
            "\n",
            "🧠 Explanation for HYPERTENSION:\n",
            "BACKGROUND: Whether hypertension affects COVID-19 patients remains unclear. METHODS: The clinical features and treatment outcomes of 80 patients with COVID-19 were retrospectively analyzed. The correlation between hypertension and COVID-19 outcomes was explored. RESULTS: Of the 80 patients enrolled, 45 were male and 35 were female. The patients with hypertension had higher rates of comorbidities including diabetes mellitus (30%) and chronic obstructive pulmonary disease (COPD) (35%) than those without hypertension. Compared to patients without hypertension, the patients with hypertension had a higher rate of smoking history (45% vs. 22%) and lower rates of educational level (30% vs. 48%). The patients with hypertension also had a higher rate of chronic kidney disease (CKD) (25% vs. 6%) and a higher incidence of cardiovascular diseases (30% vs. 13%\n",
            "\n",
            "🧠 Explanation for CARDIOVASCULAR DISEASE:\n",
            "The impact of cardiovascular diseases (CVD) on COVID-19 patients is unclear. We investigated the impact of hypertension, diabetes, and smoking on COVID-19 patients. We reviewed the medical records of hospitalized COVID-19 patients from 3 hospitals in Wuhan, China, from March 1, 2020, to April 30, 2020. We included patients with a confirmed diagnosis of COVID-19 and recorded the presence of hypertension, diabetes, and smoking history. We used multivariable linear and logistic regression models to explore the independent associations of hypertension, diabetes, and smoking with the 28-day mortality rate, and we used Cochran-Armitage Trend test to compare the mortality rates of patients with different types of CVD. We included 448 patients with a mean age of 60.6 years and a male to female ratio of 1.72. The 28-day mortality\n",
            "\n",
            "🧠 Explanation for OBESITY:\n",
            "The current mortality rate of patients suffering from coronavirus disease 2019 (COVID-19) is between 45% and 92%, with most dying within the first two weeks of the illness. In an effort to combat such an alarmingly high mortality rate, various treatment therapies such as low tidal volume ventilation strategies, corticosteroid therapy, and use of nitric oxide (NO) have been attempted in the management of patients with COVID-19. Three cases which were admitted to the ICU and confirmed to have COVID-19 were unable to be weaned from ventilatory support, and nitric oxide therapy was initiated. It improved patients' oxygenation for short periods of time but did not affect the mortality. The patients could not be weaned from the ventilator and expired. The patients could not be weaned from the ventilator and expired. The patients could not be weaned from the ventilator and expired. The\n",
            "\n",
            "🧠 Explanation for SMOKING:\n",
            "The current mortality rate of patients with COVID-19 is between 45% and 92%, with most dying within the first two weeks of the illness. In an effort to combat such an alarmingly high mortality rate, various treatment therapies such as low tidal volume ventilation strategies, corticosteroid therapy, and use of antiviral agents have been attempted in the management of patients with COVID-19. Three cases which were admitted to the ICU and confirmed to have COVID-19 were unable to be weaned from ventilatory support, and corticosteroid therapy was initiated. It improved patients' oxygenation for short periods of time but did not affect the mortality. The patients could not be weaned from the ventilator and expired. The patients could not be weaned from the ventilator and expired. The patients could not be weaned from the ventilator and expired. The patients could not be weaned from the ventilator and expired\n",
            "\n",
            "🧠 Explanation for PNEUMONIA:\n",
            "BACKGROUND: Pneumonia is one of the risk factors for COVID-19 progression. However, data on the impact of pneumonia on COVID-19 patients remains insufficient. METHODS: We conducted a systematic review and meta-analysis of observational studies reporting on the impact of pneumonia on COVID-19 patients. Pubmed, Embase, and Web of Science were searched for studies that reported on the association between pneumonia and COVID-19 progression. Data were pooled using a random-effects model. RESULTS: After applying inclusion and exclusion criteria, 18 studies involving 2,406 patients with COVID-19 were included in this meta-analysis. The pooled OR (95% CI) for COVID-19 patients with versus without pneumonia was 1.72 (1.40 2.11), and the I (2) statistic was 68.1%. The results of subgroup analysis showed that the odds of progression to severe pneumonia\n",
            "\n",
            "🧠 Explanation for IMMUNE SUPPRESSION:\n",
            "Patients with severe pneumonia caused by COVID-19 have been reported to have suppressed interferon response. To assess the impact of immune suppression on COVID-19 patients, we summarized the relevant data from the published literature and performed a systematic review and meta-analysis. PubMed, Embase, and Web of Science were searched for studies that reported on the association between immune suppression and COVID-19 patients' outcomes. Study characteristics, outcomes, and interferon responses were extracted from the publications. The pooled prevalence of immune suppression in COVID-19 patients was estimated using a random-effects model. Subgroup analyses and sensitivity analyses were conducted to assess the impact of study characteristics on the results. Thirty-seven articles with a total of 3,145 patients were included in the meta-analysis. The pooled prevalence of immune suppression was 42.5% (95% CI: 35.9% -46.9%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/biogpt_explainer_model_final.zip /content/biogpt_explainer_model_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NSw7reac0vh",
        "outputId": "8598db4c-4abe-4846-9852-b9910055e956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/biogpt_explainer_model_final/ (stored 0%)\n",
            "  adding: content/biogpt_explainer_model_final/model.safetensors (deflated 7%)\n",
            "  adding: content/biogpt_explainer_model_final/tokenizer_config.json (deflated 73%)\n",
            "  adding: content/biogpt_explainer_model_final/merges.txt (deflated 60%)\n",
            "  adding: content/biogpt_explainer_model_final/special_tokens_map.json (deflated 51%)\n",
            "  adding: content/biogpt_explainer_model_final/config.json (deflated 49%)\n",
            "  adding: content/biogpt_explainer_model_final/generation_config.json (deflated 29%)\n",
            "  adding: content/biogpt_explainer_model_final/vocab.json (deflated 70%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79v21E61q86_",
        "outputId": "900b7864-e22e-4bac-c481-b64ba41290af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zipobj = zipfile.ZipFile('/content/drive/MyDrive/biogpt_explainer_model_final.zip', 'r')\n",
        "zipobj.extractall(\"./explainer\")"
      ],
      "metadata": {
        "id": "KLeu2dFbkYko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zipobj = zipfile.ZipFile('/content/drive/MyDrive/clean_biogpt_comorbidity_model_final.zip', 'r')\n",
        "zipobj.extractall(\"./recommender\")"
      ],
      "metadata": {
        "id": "pr5BCbxKrcbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "# Rutas a tus modelos fine-tuneados\n",
        "explainer_model_path = \"/content/explainer/content/biogpt_explainer_model_final\"\n",
        "recommender_model_path = \"/content/recommender/content/clean_biogpt_comorbidity_model_final\"\n",
        "\n",
        "# Cargar modelos y tokenizers\n",
        "explainer_tokenizer = AutoTokenizer.from_pretrained(explainer_model_path)\n",
        "explainer_model = AutoModelForCausalLM.from_pretrained(explainer_model_path)\n",
        "explainer_pipe = pipeline(\"text-generation\", model=explainer_model, tokenizer=explainer_tokenizer)\n",
        "\n",
        "recommender_tokenizer = AutoTokenizer.from_pretrained(recommender_model_path)\n",
        "recommender_model = AutoModelForCausalLM.from_pretrained(recommender_model_path)\n",
        "recommender_pipe = pipeline(\"text-generation\", model=recommender_model, tokenizer=recommender_tokenizer)\n",
        "\n",
        "# Lista de comorbilidades\n",
        "comorbidities = [\"diabetes\", \"asthma\", \"hypertension\", \"cardiovascular disease\", \"obesity\", \"smoking\"]\n",
        "\n",
        "# Generar reporte\n",
        "for cond in comorbidities:\n",
        "    # Prompt para explicación técnica\n",
        "    explainer_prompt = (\n",
        "        f\"<|startoftext|>\\n\"\n",
        "        f\"[PROMPT]: How does {cond} affect COVID-19 outcomes?\\n\"\n",
        "        \"[EXPLANATION]:\"\n",
        "    )\n",
        "    expl = explainer_pipe(explainer_prompt, max_length=300, do_sample=True, temperature=0.7)[0]['generated_text']\n",
        "    explanation = expl.split(\"[EXPLANATION]:\")[-1].split(\"<|endoftext|>\")[0].strip()\n",
        "\n",
        "    # Prompt para recomendación práctica\n",
        "    recommender_prompt = (\n",
        "        f\"<|startoftext|>\\n\"\n",
        "        f\"[CONDITION]: {cond}\\n\"\n",
        "        \"[PROMPT]: Provide a clear and actionable health recommendation for a COVID-19 patient with this condition.\\n\"\n",
        "        f\"[RECOMMENDATION]: For patients with {cond}, it is important to\"\n",
        "    )\n",
        "    rec = recommender_pipe(recommender_prompt, max_length=150, do_sample=True, temperature=0.6, truncation=True)[0]['generated_text']\n",
        "    recommendation = rec.split(\"[RECOMMENDATION]:\")[-1].split(\"<|endoftext|>\")[0].strip()\n",
        "\n",
        "    # Imprimir resultados\n",
        "    print(f\"\\n============================\")\n",
        "    print(f\"🧠 MEDICAL EXPLANATION - {cond.upper()}:\\n{explanation}\")\n",
        "    print(f\"\\n💊 RECOMMENDATION - {cond.upper()}:\\n{recommendation}\")\n"
      ],
      "metadata": {
        "id": "mZkdBtBkePii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f507f9-9ba5-4040-87a1-f14bd322c281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================\n",
            "🧠 MEDICAL EXPLANATION - DIABETES:\n",
            "The current mortality rate of patients with COVID-19 is between 45% and 92%, with most dying within the first two weeks of the illness. Worldwide, a majority of cases occur in patients with comorbid conditions such as hypertension, diabetes, and smoking history. In addition, patients with diabetes are more likely to progress to chronic obstructive pulmonary disease (COPD) and respiratory failure requiring ventilatory support. Finally, it has been shown that severe pneumonia and ARDS may occur in patients with COVID-19 due to the presence of influenza A virus. Therefore, it has become imperative to evaluate the impact of diabetes on COVID-19 patients. Diabetics are at a higher risk of developing pneumonia and ARDS, but they may also have a better outcome following severe pneumonia and ARDS. In this review, we will summarize the current knowledge about the impact of diabetes on COVID-19 patients, with a particular focus on the severity of pneumonia and ARDS. We will also highlight the potential pathways by which diabetes may influence COVID-19 patients, including the way in which it may affect COVID-19 patients by modifying the course of the viral infection, its transmission, and its impact on the host immune system. Finally, we will discuss the implications of these findings for the management of patients with diabetes during the course of the COVID-19 pandemic.\n",
            "\n",
            "💊 RECOMMENDATION - DIABETES:\n",
            "For patients with diabetes, it is important to follow the following guidelines: https: / / www.healthtap.com / blog / covid-19-care-guidelines / preventing-covid-19Probably worthwhile to first assist you with your understanding of the risks / benefits of taking the test results to your PCP ② Do you have a fever? Would you like to video or text chat with me? Would you like to video or text chat with me? Would you like to\n",
            "\n",
            "============================\n",
            "🧠 MEDICAL EXPLANATION - ASTHMA:\n",
            "BACKGROUND: Asthma patients are at an increased risk of severe COVID-19 disease. Whether comorbid asthma affects COVID-19 patients has not been determined. METHODS: This analysis included patients with COVID-19 admitted to a tertiary care center in Wuhan, China. The primary outcome was a composite of ICU admission, mechanical ventilation, or death. The secondary outcome was a composite of ICU admission, mechanical ventilation, or death during the initial COVID-19 course. RESULTS: Among 2,148 patients with COVID-19, 1,266 (57.7%) had comorbid asthma. Compared to non-asthmatics, asthmatics were more likely to be male (65.9% vs. 51.3%), non-smokers (61.1% vs. 45.9%), non-obese (BMI 18.5-29.9 kg / m CONCLUSIONS: Comorbidities including asthma are common in patients with COVID-19. Asthma is an independent risk factor for severe disease and an adverse impact on COVID-19 patients.\n",
            "\n",
            "💊 RECOMMENDATION - ASTHMA:\n",
            "For patients with asthma, it is important to have a COVID-19-specific health recommendation. If you have a sore throat and a fever, call your General Physician.....................................................................\n",
            "\n",
            "============================\n",
            "🧠 MEDICAL EXPLANATION - HYPERTENSION:\n",
            "Evidence is rapidly accumulating implicating hypertension as a risk factor for severe disease and death in patients with COVID-19. However, the mechanisms underlying this association are not well understood. This review article summarizes the current literature on the impact of hypertension on COVID-19 patients and discusses potential mechanisms that may underlie this association. RECENT FINDINGS: Hypertensive patients are more likely to experience a higher burden of severe pneumonia and acute respiratory distress syndrome (ARDS) compared to non-hypertensive patients with COVID-19. Additionally, hypertension appears to affect COVID-19 patients differently than previously reported. These differences may be explained by the presence of comorbid conditions (diabetes, chronic obstructive pulmonary disease, and smoking) that are commonly associated with hypertension in patients with COVID-19. SUMMARY: Hypertension is a risk factor for a worse COVID-19 outcome. The mechanisms underlying this association are unclear. Hypertension may affect COVID-19 patients by increasing the burden of virus exposure or by increasing the severity of pneumonia. However, further studies with larger samples sizes and a greater variety of hypertensive patients are needed to confirm these findings and to determine the underlying mechanisms.\n",
            "\n",
            "💊 RECOMMENDATION - HYPERTENSION:\n",
            "For patients with hypertension, it is important to follow appropriate gudelines. If you are older than 70, have chronic conditions (diabetes, heart attack or use of ACEI or ARB), you are at higher risk for complications, and you are using more than one drug to treat you, you must take precautions to minimize contact with people so as to avoid contacting the virus............................\n",
            "\n",
            "============================\n",
            "🧠 MEDICAL EXPLANATION - CARDIOVASCULAR DISEASE:\n",
            "BACKGROUND: Patients with comorbid conditions have a worse prognosis in coronavirus disease (COVID-19). However, the relationship between cardiovascular disease (CVD) and COVID-19 patients remains unclear. METHODS: This was a multicenter, retrospective cohort study that included consecutive patients with confirmed COVID-19. The primary outcome was a composite of cardiovascular death or intubation. The association between comorbidities and the primary outcome was assessed using multivariable adjusted logistic regression models. RESULTS: Among the 2,145 patients enrolled, the mean age was 67.8 years, and 80.3% were men. The most common comorbidities were hypertension (30.5%), diabetes (12.8%), and smoking (12.7%). The most common cardiovascular diagnoses were acute myocardial infarction (7.8%), heart failure (8.6%), and atrial fibrillation (7.8%). The overall median [interquartile range] duration of symptoms was 3 [2, 5] days and the median number of days from symptom onset to hospital admission was 8 [4, 14] days. After multivariable adjustment, hypertension (odds ratio [95% confidence interval]: 0.93 [0.88 0.97]), diabetes (0.93 [0.87 0.96]), and smoking (0.88 [0.81 0.96]) were each associated with a lower likelihood of the primary outcome. After further adjustment for the presence of acute respiratory distress syndrome,\n",
            "\n",
            "💊 RECOMMENDATION - CARDIOVASCULAR DISEASE:\n",
            "For patients with cardiovascular disease, it is important to keep A1c as low as possible, and increase exercise and dietary supplements that increase resistance to viruses. Stay healthy......................................, increase your daily fresh air, increase your level of activity, and increase your level of resistance to viruses.. Would you like to video or text\n",
            "\n",
            "============================\n",
            "🧠 MEDICAL EXPLANATION - OBESITY:\n",
            "BACKGROUND: Growing evidence links obesity and severe respiratory viral infections. However, whether obesity impacts COVID-19 patients' outcomes remains unclear. METHODS: The study included 371 consecutive patients with confirmed COVID-19 infection who were admitted to a tertiary medical center in Wuhan, China, from January 22, 2020, to February 25, 2020. Patients were stratified into two groups according to their body mass index (BMI): obese (n = 108) and non-obese (n = 261). The primary outcome was the 30-day mortality rate. RESULTS: The 30-day mortality rate was significantly higher in the obese than in the non-obese group (29.6% vs 7.8%, p < 0.001). Logistic regression analysis identified age (odds ratio [95% confidence interval]: 1.025 [1.019 1.305], p < 0.001), hypertension (2.026 [1.016 3.797], p = 0.04), diabetes (1.914 [1.019 3.594], p = 0.04), and smoking (1.984 [1.042 3.594], p = 0.02) as independent risk factors for 30-day mortality. After adjusting for potential confounders, the odds of dying in the obese group was 2.073 [1.021 3.992], p = 0.04). CONCLUSIONS: Obesity\n",
            "\n",
            "💊 RECOMMENDATION - OBESITY:\n",
            "For patients with obesity, it is important to follow appropriate weight-management guidelines. Maintain adequate hydration, seek medical attention for dehydration, and then monitor your glucose and lipid levels. If you are in a medical condition like diabetes, they should be closely monitored. If you are not well controlled, they should quire if they have any symptoms. Good luck..............................\n",
            "\n",
            "============================\n",
            "🧠 MEDICAL EXPLANATION - SMOKING:\n",
            "BACKGROUND: The impact of smoking on the COVID-19 patients is not clear. METHODS: This study included 2,145 patients with confirmed COVID-19 admitted to an infectious disease hospital between March 17, 2020, and January 15, 2020. Multivariate logistic regression and Cox proportional hazards regression were used to analyze the impact of smoking on in-hospital mortality and the time to virus clearance, respectively. RESULTS: Smokers were more likely to be male, non-smokers, non-obese, and non-drinkers. Compared to non-smokers, the adjusted odds ratio (95% confidence interval) for in-hospital mortality was 1.52 (1.01, 2.24) for smokers. Compared to non-drinkers, the adjusted hazard ratio (95% confidence interval) for mortality was 1.52 (1.08, 2.13) for those who were active smokers. Compared to patients who were non-smokers, the adjusted hazard ratio (95% confidence interval) for mortality for smokers was 1.52 (1.09, 2.09) for those who were active smokers. Compared to patients who cleared the virus within seven days, the adjusted hazard ratio (95% confidence interval) for mortality was 1.77 (1.31, 2.33) for patients who cleared the virus between eight and 14 days and 2.41 (1.30, 4.39) for patients who cleared the virus between 15 and 28 days. Compared to non-smokers, the\n",
            "\n",
            "💊 RECOMMENDATION - SMOKING:\n",
            "For patients with smoking, it is important to give them a health recommendation. If you have a sore throat and a fever, call your General Physician and give him or her other advice..................................................................\n"
          ]
        }
      ]
    }
  ]
}